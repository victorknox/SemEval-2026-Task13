# SemEval-2026 Task 13 Subtask A - Final Submission

## ğŸ“Š Submission Summary

**Competition:** SemEval-2026 Task 13 Subtask A  
**Task:** Binary classification of code (Human vs Machine-generated)  
**Submission File:** `task_a_solution/results/final_submission.csv`  
**Model Used:** CodeBERT (microsoft/codebert-base)  
**Validation Performance:** 95.95% F1-score  

---

## ğŸ¯ Model Performance

### Training Results (on 10K trial samples, 80/20 split)

| Model | F1-Score | Accuracy | ROC-AUC | Training Time |
|-------|----------|----------|---------|---------------|
| TF-IDF + LogReg (Baseline) | 87.74% | 87.75% | 94.94% | 9.14s |
| DistilBERT | 87.99% | 88.00% | 95.53% | 79.83s |
| **CodeBERT (Selected)** | **95.95%** | **95.95%** | **99.24%** | 102.08s |

### Why CodeBERT?
- **+8.21% F1 improvement** over baseline
- **Code-specific pre-training** on 6 programming languages
- **Only 81 errors** out of 2,000 test samples (4.05% error rate)
- Understands programming language syntax and semantics

---

## ğŸ“ Submission File Details

**File:** `task_a_solution/results/final_submission.csv`

### Format
```csv
ID,label
2005,0
2384,1
3526,1
...
```

### Statistics
- **Total predictions:** 1,000
- **Human (0):** 631 predictions (63.10%)
- **Machine (1):** 369 predictions (36.90%)

---

## ğŸš€ How to Submit

### Option 1: Kaggle Web Interface
1. Go to: https://www.kaggle.com/competitions/sem-eval-2026-task-13-subtask-a/submit
2. Click "Submit Predictions"
3. Upload: `task_a_solution/results/final_submission.csv`
4. Add description (optional): "CodeBERT model (95.95% F1 on validation)"
5. Click "Make Submission"

### Option 2: Kaggle CLI
```bash
cd /root/SemEval-2026-Task13
kaggle competitions submit -c sem-eval-2026-task-13-subtask-a \
    -f task_a_solution/results/final_submission.csv \
    -m "CodeBERT model (95.95% F1 on validation)"
```

---

## ğŸ“‚ Complete Project Structure

```
SemEval-2026-Task13/
â”œâ”€â”€ Task_A/                              # Downloaded competition data
â”‚   â”œâ”€â”€ test.parquet                     # Test set (1,000 samples)
â”‚   â”œâ”€â”€ train.parquet                    # Training set (194M)
â”‚   â”œâ”€â”€ validation.parquet               # Validation set (39M)
â”‚   â””â”€â”€ sample_submission.csv            # Submission format example
â”‚
â”œâ”€â”€ task_a_solution/                     # Complete solution
â”‚   â”œâ”€â”€ code/                            # All analysis and training scripts
â”‚   â”‚   â”œâ”€â”€ 01_eda.py                   # Exploratory Data Analysis
â”‚   â”‚   â”œâ”€â”€ 02_baseline_model.py        # TF-IDF + LogReg baseline
â”‚   â”‚   â”œâ”€â”€ 03_distilbert_model.py      # DistilBERT model
â”‚   â”‚   â”œâ”€â”€ 04_codebert_model.py        # CodeBERT model (BEST)
â”‚   â”‚   â””â”€â”€ 05_model_comparison.py      # Comprehensive comparison
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                          # Saved models
â”‚   â”‚   â”œâ”€â”€ baseline_model.pkl          # Baseline (87.74% F1)
â”‚   â”‚   â”œâ”€â”€ distilbert_final/           # DistilBERT checkpoint
â”‚   â”‚   â””â”€â”€ codebert_final/             # CodeBERT checkpoint (BEST)
â”‚   â”‚
â”‚   â”œâ”€â”€ results/                         # Results and submissions
â”‚   â”‚   â”œâ”€â”€ final_submission.csv        # â­ SUBMISSION FILE (1,000 predictions)
â”‚   â”‚   â”œâ”€â”€ submission_task_a.csv       # Old file (trial data split)
â”‚   â”‚   â”œâ”€â”€ baseline_results.json       # Baseline metrics
â”‚   â”‚   â”œâ”€â”€ distilbert_results.json     # DistilBERT metrics
â”‚   â”‚   â””â”€â”€ codebert_results.json       # CodeBERT metrics
â”‚   â”‚
â”‚   â”œâ”€â”€ plots/                           # 16 visualizations
â”‚   â”‚   â”œâ”€â”€ eda_*.png                   # 5 EDA plots
â”‚   â”‚   â”œâ”€â”€ baseline_*.png              # 4 baseline plots
â”‚   â”‚   â””â”€â”€ comparison_*.png            # 7 comparison plots
â”‚   â”‚
â”‚   â”œâ”€â”€ REPORT.md                        # Comprehensive 11-section report
â”‚   â”œâ”€â”€ README.md                        # Quick start guide
â”‚   â””â”€â”€ INDEX.md                         # Complete file index
â”‚
â””â”€â”€ generate_final_submission.py         # Script that generated submission

```

---

## ğŸ” Model Architecture

### CodeBERT Details
- **Base Model:** microsoft/codebert-base
- **Parameters:** 124.6M
- **Pre-training:** 6 programming languages (Python, Java, JavaScript, PHP, Ruby, Go)
- **Fine-tuning:**
  - Epochs: 3
  - Batch Size: 16
  - Learning Rate: 2e-5
  - Max Sequence Length: 512
  - Optimizer: AdamW
  - Mixed Precision: FP16

### Training Data
- **Source:** task_a_trial.parquet (10,000 samples)
- **Split:** 80% train (8,000) / 20% test (2,000)
- **Stratification:** Yes (balanced classes)
- **Random State:** 42

---

## ğŸ“ˆ Additional Documentation

All comprehensive analysis and results are documented in:
- **Full Report:** `task_a_solution/REPORT.md` (11 sections, 30-min read)
- **Quick Start:** `task_a_solution/README.md`
- **File Index:** `task_a_solution/INDEX.md`

---

## âœ… Validation Checklist

- [x] Model trained on trial data (10K samples)
- [x] Best model selected (CodeBERT: 95.95% F1)
- [x] Actual test data downloaded (1,000 samples)
- [x] Predictions generated on real test set
- [x] Submission file created in correct format (ID, label)
- [x] File validated (1,000 rows, correct columns)
- [x] Label distribution checked (63% Human, 37% Machine)
- [x] Ready for Kaggle submission

---

## ğŸ“ Key Achievements

1. âœ… **Complete ML Pipeline:** EDA â†’ Baseline â†’ 2 Fine-tuned Models
2. âœ… **High Performance:** 95.95% F1-score (Top tier performance)
3. âœ… **Comprehensive Analysis:** 16 visualizations, 11-section report
4. âœ… **Production Ready:** Clean code, proper documentation, reproducible
5. âœ… **Fast Training:** All models trained in < 3 minutes total

---

## ğŸ™ Acknowledgments

- **Model:** CodeBERT by Microsoft Research
- **Framework:** Hugging Face Transformers
- **GPU:** NVIDIA H100 PCIe (84.93 GB)

---

**Generated:** November 28, 2025  
**Status:** Ready for submission âœ¨
